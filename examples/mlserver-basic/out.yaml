---
# Source: mlserver-basic/charts/ai-workloads/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: aiw-ai-workloads-sa
  annotations:
    azure.workload.identity/client-id: 3b3c6b2c-1a2d-4e6a-9f22-03f2e7c1d8ab
---
# Source: mlserver-basic/charts/ai-workloads/templates/configmap-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: aiw-ai-workloads-mlserver-a-settings
  labels:
    app.kubernetes.io/name: mlserver-a
    app.kubernetes.io/instance: aiw
    app.kubernetes.io/component: mlserver
    app.kubernetes.io/managed-by: "ai-workloads-helm"
    app.kubernetes.io/part-of: ai-workloads
data:
  settings.json: |
    {
      "models": [
        {
          "name": "fraud-detector",
          "implementation": "mlserver_sklearn.SKLearnModel",
          "parameters": {
            "uri": "/models/fraud-detector"
          }
        }
      ],
      "logLevel": "INFO"
    }
---
# Source: mlserver-basic/charts/ai-workloads/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: aiw-ai-workloads-mlserver-a
  labels:
    app.kubernetes.io/name: mlserver-a
    app.kubernetes.io/instance: aiw
    app.kubernetes.io/component: mlserver
    app.kubernetes.io/managed-by: "ai-workloads-helm"
    app.kubernetes.io/part-of: ai-workloads
    
    azure.workload.identity/use: "true"
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: mlserver-a
    app.kubernetes.io/instance: aiw
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      protocol: TCP
---
# Source: mlserver-basic/charts/ai-workloads/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aiw-ai-workloads-mlserver-a
  labels:
    app.kubernetes.io/name: mlserver-a
    app.kubernetes.io/instance: aiw
    app.kubernetes.io/component: mlserver
    app.kubernetes.io/managed-by: "ai-workloads-helm"
    app.kubernetes.io/part-of: ai-workloads
    
    azure.workload.identity/use: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: mlserver-a
      app.kubernetes.io/instance: aiw
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mlserver-a
        app.kubernetes.io/instance: aiw
        app.kubernetes.io/component: mlserver
        app.kubernetes.io/part-of: ai-workloads
        azure.workload.identity/use: "true"
      annotations:
        {}
    spec:
      
      
      serviceAccountName: aiw-ai-workloads-sa
      restartPolicy: Always
      
      containers:
        - name: mlserver-a
          image: "ghcr.io/acme/mlserver-a:v1.1.0"
          imagePullPolicy: IfNotPresent
          command:
            - mlserver
          args:
            - start
            - --settings
            - /etc/settings/settings.json
          env:
            - name: MLSERVER_HTTP_PORT
              value: "8000"
          livenessProbe:
            httpGet:
              path: /v2/health/live
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 15
            timeoutSeconds: 2
          readinessProbe:
            httpGet:
              path: /v2/health/ready
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 2
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 256Mi
          volumeMounts:
            - mountPath: /models
              name: model-storage
            - name: app-settings
              mountPath: "/etc/settings"
      volumes:
        - emptyDir: {}
          name: model-storage
        - name: app-settings
          configMap:
            name: "aiw-ai-workloads-mlserver-a-settings"
---
# Source: mlserver-basic/charts/ai-workloads/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: aiw-ai-workloads-mlserver-a-hpa
  labels:
    app.kubernetes.io/name: mlserver-a
    app.kubernetes.io/instance: aiw
    app.kubernetes.io/component: mlserver
    app.kubernetes.io/managed-by: "ai-workloads-helm"
    app.kubernetes.io/part-of: ai-workloads
    ai-workloads/hpa-profile: "standard"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: aiw-ai-workloads-mlserver-a
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - resource:
        name: cpu
        target:
          averageUtilization: 60
          type: Utilization
      type: Resource
