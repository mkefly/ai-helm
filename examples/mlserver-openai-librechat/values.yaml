ai-workloads:
  serviceAccount:
    create: true
    annotations:
      azure.workload.identity/client-id: 3b3c6b2c-1a2d-4e6a-9f22-03f2e7c1d8ab

  apps:
    - name: runtime-openai
      kind: mlserver
      infraProfile: cpu-small

      image:
        repository: ghcr.io/acme/runtime-openai
        tag: v1.0.0

      service:
        enabled: true
        type: ClusterIP
        ports:
          - name: http
            port: 8000
            protocol: TCP

      env:
        - name: LOG_LEVEL
          value: info

      hpa:
        enabled: true
        minReplicas: 1
        maxReplicas: 10
        metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 60

      labels:
        azure.workload.identity/use: "true"

    - name: librechat-backend
      kind: librechat
      infraProfile: cpu-small

      image:
        repository: ghcr.io/librechat/librechat
        tag: latest

      service:
        enabled: true
        type: ClusterIP
        ports:
          - name: http
            port: 3000
            protocol: TCP
        skipVirtualService: true

      env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: librechat-openai-key
              key: api-key
        - name: OPENAI_API_BASE
          value: '{{ printf "http://%s:8000/v1" (include "ai-workloads.appName" (dict "root" $ "app" (index $.Values.apps 0))) }}'
        - name: OPENAI_API_TYPE
          value: openai
        - name: OPENAI_API_VERSION
          value: "2023-05-15"

      hpa:
        enabled: true
        minReplicas: 1
        maxReplicas: 5
        metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 60

      labels:
        azure.workload.identity/use: "true"

    - name: librechat
      kind: oauth2-proxy
      infraProfile: cpu-small

      image:
        repository: quay.io/oauth2-proxy/oauth2-proxy
        tag: v7.6.0

      service:
        enabled: true
        type: ClusterIP
        ports:
          - name: http
            port: 4180
            protocol: TCP

      args:
        - --http-address=0.0.0.0:4180
        - --provider=oidc
        - --oidc-issuer-url=https://login.microsoftonline.com/8f1c4e9a-7d49-4a7a-9a5b-2d4f2e6b9c01/v2.0
        - --scope=openid,profile,email
        - --redirect-url=https://ai.example.com/apps/librechat/oauth2/callback
        - --email-domain=example.com
        - --upstream=http://aiw-ai-workloads-librechat-backend:3000
        - --cookie-secure=true
        - --cookie-samesite=lax
        - --cookie-refresh=1h
        - --cookie-expire=12h
        - --cookie-http-only=true
        - --pass-access-token=true
        - --set-authorization-header=true

      env:
        - name: OAUTH2_PROXY_CLIENT_ID
          value: 3b3c6b2c-1a2d-4e6a-9f22-03f2e7c1d8ab
        - name: OAUTH2_PROXY_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: oauth2-proxy-client
              key: client-secret
        - name: OAUTH2_PROXY_COOKIE_SECRET
          valueFrom:
            secretKeyRef:
              name: oauth2-proxy-cookie
              key: cookie-secret

      labels:
        azure.workload.identity/use: "true"

  batchTasks: []
